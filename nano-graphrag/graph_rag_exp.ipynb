{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nano_graphrag import GraphRAG, QueryParam \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from nano_graphrag import GraphRAG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ Hugging Face í† í° ê°€ì ¸ì˜¤ê¸°\n",
    "hf_token = os.getenv(\"HUGGINGFACE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "/Users/mac/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:nano-graphrag:Load KV full_docs with 0 data\n",
      "INFO:nano-graphrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-graphrag:Load KV llm_response_cache with 8 data\n",
      "INFO:nano-graphrag:Load KV community_reports with 0 data\n",
      "INFO:nano-graphrag:Loaded graph from ./llama_graph_data/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges\n",
      "INFO:nano-vectordb:Load (0, 384) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 384, 'metric': 'cosine', 'storage_file': './llama_graph_data/vdb_entities.json'} 0 data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# nano-graphragì—ì„œ ìš”êµ¬í•˜ëŠ” ë˜í•‘\n",
    "def wrap_embedding_func_with_attrs(embedding_dim, max_token_size):\n",
    "    def decorator(func):\n",
    "        func.embedding_dim = embedding_dim\n",
    "        func.max_token_size = max_token_size\n",
    "        return func\n",
    "    return decorator\n",
    "\n",
    "@wrap_embedding_func_with_attrs(embedding_dim=384, max_token_size=512)\n",
    "async def local_embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    return model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "async def my_custom_llm(prompt, system_prompt=None, history_messages=[], **kwargs):\n",
    "    response = await ollama_complete_if_cache(\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        model= 'llama3',\n",
    "        **kwargs\n",
    "    )\n",
    "    print(\"ğŸ§  LLaMA3 ì‘ë‹µ:\", response)\n",
    "    return response\n",
    "\n",
    "# âœ… GraphRAG ê°ì²´ ìƒì„±\n",
    "graph_func = GraphRAG(\n",
    "    working_dir=\"./llama_graph_data\",\n",
    "    best_model_func=my_custom_llm,             # ğŸ‘‰ Ollama ê¸°ë°˜ LLM ì‚¬ìš©\n",
    "    embedding_func=local_embedding_func        # ğŸ‘‰ SentenceTransformer ê¸°ë°˜ ë¡œì»¬ ì„ë² ë”©\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:[New Docs] inserting 1 docs\n",
      "INFO:nano-graphrag:[New Chunks] inserting 4 chunks\n",
      "INFO:nano-graphrag:[Entity Extraction]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“£ [ollama_complete] í•¨ìˆ˜ í˜¸ì¶œë¨!!\n",
      "ğŸ“ Full prompt length (chars): 6038\n",
      "ğŸ“£ [ollama_complete] í•¨ìˆ˜ í˜¸ì¶œë¨!!\n",
      "ğŸ“ Full prompt length (chars): 5943\n",
      "ğŸ“£ [ollama_complete] í•¨ìˆ˜ í˜¸ì¶œë¨!!\n",
      "ğŸ“ Full prompt length (chars): 5797\n",
      "ğŸ“£ [ollama_complete] í•¨ìˆ˜ í˜¸ì¶œë¨!!\n",
      "ğŸ“ Full prompt length (chars): 1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLaMA3 ì‘ë‹µ: Here is the output in the required format:\n",
      "\n",
      "## (\"entity\"<|>Master Scrooge<|>person<|>He was a bitter old man with a heart full of coldness and stone. He had no love for Christmas or its traditions, and he spent most of his time alone, away from his nephew's family.)\n",
      "## (\"entity\"<|>Schoolmaster<|>person<|>He was the master of a school where children were forced to learn. He was a stern man who liked to keep people in line.)\n",
      "## (\"entity\"<|>Ghost<|>person<|>She was a ghostly figure who appeared to Scrooge and took him on a journey through time, showing him the errors of his ways and trying to make him see the error of his ways.)\n",
      "## (\"entity\"<|>Fezziwig<|>organization<|>He was an old gentleman who used to be a kind and generous employer. He loved Christmas and liked to celebrate it with his employees.)\n",
      "## (\"relationship\"<|>Master Scrooge<|>Schoolmaster<|>The schoolmaster shook hands with Master Scrooge, which made him nervous and uneasy in his mind.<|>5)\n",
      "## (\"relationship\"<|>Master Scrooge<|>Ghost<|>The Ghost took Scrooge on a journey through time, showing him the errors of his ways and trying to make him see the error of his ways.<|>8)\n",
      "## (\"relationship\"<|>Fezziwig<|>Scrooge<|>Fezziwig was an old employer of Scrooge's, who used to be kind and generous but had become bitter and cold-hearted over time.<|>7)\n",
      "\n",
      "##<|>COMPLETE|>\n",
      "ğŸ“£ [ollama_complete] í•¨ìˆ˜ í˜¸ì¶œë¨!!\n",
      "ğŸ“ Full prompt length (chars): 7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLaMA3 ì‘ë‹µ: Here is the output:\n",
      "\n",
      "## \"entity\"<|>\"Scrooge\"<|>person<|>\"A wealthy miserly old man who has been visited by three spirits\"<|>\n",
      "\n",
      "## \"entity\"<|>\"The Spirit\"<|>event<|>\"An ethereal being who appears to Scrooge and guides him on a journey through his past, present, and future\"<|>\n",
      "\n",
      "## \"relationship\"<|>\"Scrooge\"<|>\"The Spirit\"<|>\"The Spirit visits Scrooge in the middle of the night and takes him on a journey through his past, present, and future\"<|>7\n",
      "\n",
      "## \"entity\"<|>\"Bob Cratchit\"<|>person<|>\"A kind and gentle man who is Scrooge's employee and the father of Tiny Tim\"<|>\n",
      "\n",
      "## \"relationship\"<|>\"Scrooge\"<|>\"Bob Cratchit\"<|>\"Scrooge, as his employer, has treated Bob Cratchit poorly and taken advantage of him\"<|>5\n",
      "\n",
      "## \"entity\"<|>\"Tiny Tim\"<|>person<|>\"A young boy who is the son of Bob Cratchit and has a disability that leaves him unable to walk without crutches\"<|>\n",
      "\n",
      "## \"relationship\"<|>\"Scrooge\"<|>\"Tiny Tim\"<|>\"Scrooge, despite his cold heart, is moved by the sight of Tiny Tim and begins to see the error of his ways\"<|>8\n",
      "\n",
      "## \"entity\"<|>\"London\"<|>geo<|>\"A city where Scrooge lives and works as a moneylender\"<|>\n",
      "\n",
      "## \"relationship\"<|>\"Scrooge\"<|>\"London\"<|>\"Scrooge is a part of London society, but his cold heart and miserly ways have isolated him from others\"<|>6\n",
      "\n",
      "## \"entity\"<|>\"Christmas\"<|>event<|>\"A holiday that Scrooge has always disliked and avoided, but which he begins to see as a time for joy and giving\"<|>\n",
      "\n",
      "## \"relationship\"<|>\"Scrooge\"<|>\"Christmas\"<|>\"Scrooge's attitude towards Christmas changes throughout the story, from one of disdain to one of appreciation and joy\"<|>9\n",
      "\n",
      "## COMPLETE|>\n",
      "ğŸ“£ [ollama_complete] í•¨ìˆ˜ í˜¸ì¶œë¨!!\n",
      "ğŸ“ Full prompt length (chars): 7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Writing graph with 0 nodes, 0 edges\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_backends/anyio.py:32\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     26\u001b[39m exc_map = {\n\u001b[32m     27\u001b[39m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ReadTimeout,\n\u001b[32m     28\u001b[39m     anyio.BrokenResourceError: ReadError,\n\u001b[32m     29\u001b[39m     anyio.ClosedResourceError: ReadError,\n\u001b[32m     30\u001b[39m     anyio.EndOfStream: ReadError,\n\u001b[32m     31\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manyio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfail_after\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m./book.txt\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     text = f.read()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mgraph_func\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ìë™ìœ¼ë¡œ chunking, graph êµ¬ì„±\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/graphrag.py:221\u001b[39m, in \u001b[36mGraphRAG.insert\u001b[39m\u001b[34m(self, string_or_strings)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minsert\u001b[39m(\u001b[38;5;28mself\u001b[39m, string_or_strings):\n\u001b[32m    220\u001b[39m     loop = always_get_an_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mainsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring_or_strings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/graphrag.py:310\u001b[39m, in \u001b[36mGraphRAG.ainsert\u001b[39m\u001b[34m(self, string_or_strings)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# ---------- extract/summary entity and upsert to graph\u001b[39;00m\n\u001b[32m    309\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m[Entity Extraction]...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m maybe_new_kg = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.entity_extraction_func(\n\u001b[32m    311\u001b[39m     inserting_chunks,\n\u001b[32m    312\u001b[39m     knwoledge_graph_inst=\u001b[38;5;28mself\u001b[39m.chunk_entity_relation_graph,\n\u001b[32m    313\u001b[39m     entity_vdb=\u001b[38;5;28mself\u001b[39m.entities_vdb,\n\u001b[32m    314\u001b[39m     global_config=asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m    315\u001b[39m     using_amazon_bedrock=\u001b[38;5;28mself\u001b[39m.using_amazon_bedrock,\n\u001b[32m    316\u001b[39m )\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maybe_new_kg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    318\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mNo new entities found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_op.py:388\u001b[39m, in \u001b[36mextract_entities\u001b[39m\u001b[34m(chunks, knwoledge_graph_inst, entity_vdb, global_config, using_amazon_bedrock)\u001b[39m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(maybe_nodes), \u001b[38;5;28mdict\u001b[39m(maybe_edges)\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# use_llm_func is wrapped in ascynio.Semaphore, limiting max_async callings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    389\u001b[39m     *[_process_single_content(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ordered_chunks]\n\u001b[32m    390\u001b[39m )\n\u001b[32m    391\u001b[39m \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# clear the progress bar\u001b[39;00m\n\u001b[32m    392\u001b[39m maybe_nodes = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_op.py:325\u001b[39m, in \u001b[36mextract_entities.<locals>._process_single_content\u001b[39m\u001b[34m(chunk_key_dp)\u001b[39m\n\u001b[32m    322\u001b[39m hint_prompt = entity_extract_prompt.format(**context_base, input_text=content)\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# print(hint_prompt[:1000])\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m final_result = \u001b[38;5;28;01mawait\u001b[39;00m use_llm_func(hint_prompt)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(final_result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    327\u001b[39m     final_result = final_result[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_utils.py:251\u001b[39m, in \u001b[36mlimit_async_func_call.<locals>.final_decro.<locals>.wait_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(waitting_time)\n\u001b[32m    250\u001b[39m __current_size += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    252\u001b[39m __current_size -= \u001b[32m1\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mmy_custom_llm\u001b[39m\u001b[34m(prompt, system_prompt, history_messages, **kwargs)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmy_custom_llm\u001b[39m(prompt, system_prompt=\u001b[38;5;28;01mNone\u001b[39;00m, history_messages=[], **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m ollama_complete_if_cache(\n\u001b[32m     17\u001b[39m         prompt,\n\u001b[32m     18\u001b[39m         system_prompt=system_prompt,\n\u001b[32m     19\u001b[39m         history_messages=history_messages,\n\u001b[32m     20\u001b[39m         model= \u001b[33m'\u001b[39m\u001b[33mllama3\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     21\u001b[39m         **kwargs\n\u001b[32m     22\u001b[39m     )\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ§  LLaMA3 ì‘ë‹µ:\u001b[39m\u001b[33m\"\u001b[39m, response)\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_llm.py:148\u001b[39m, in \u001b[36mollama_complete_if_cache\u001b[39m\u001b[34m(prompt, system_prompt, history_messages, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m if_cache_return \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m if_cache_return[\u001b[33m\"\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m ollama_complete(prompt, system_prompt, history_messages, **kwargs)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hashing_kv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hashing_kv.upsert({args_hash: {\u001b[33m\"\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m\"\u001b[39m: response, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mollama-llama3\u001b[39m\u001b[33m\"\u001b[39m}})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_llm.py:121\u001b[39m, in \u001b[36mollama_complete\u001b[39m\u001b[34m(prompt, system_prompt, history_messages, model, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Ollama HTTP POST ìš”ì²­\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m httpx.AsyncClient(timeout=\u001b[32m180\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m client.post(\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434/api/generate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    123\u001b[39m         json={\n\u001b[32m    124\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    125\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: full_prompt,\n\u001b[32m    126\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# ìŠ¤íŠ¸ë¦¬ë° êº¼ë‘ë©´ ì „ì²´ ì‘ë‹µ ë°˜í™˜\u001b[39;00m\n\u001b[32m    127\u001b[39m         }\n\u001b[32m    128\u001b[39m     )\n\u001b[32m    129\u001b[39m     response.raise_for_status()\n\u001b[32m    130\u001b[39m     result = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1859\u001b[39m, in \u001b[36mAsyncClient.post\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1840\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1852\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1853\u001b[39m ) -> Response:\n\u001b[32m   1854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[33;03m    Send a `POST` request.\u001b[39;00m\n\u001b[32m   1856\u001b[39m \n\u001b[32m   1857\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1861\u001b[39m         url,\n\u001b[32m   1862\u001b[39m         content=content,\n\u001b[32m   1863\u001b[39m         data=data,\n\u001b[32m   1864\u001b[39m         files=files,\n\u001b[32m   1865\u001b[39m         json=json,\n\u001b[32m   1866\u001b[39m         params=params,\n\u001b[32m   1867\u001b[39m         headers=headers,\n\u001b[32m   1868\u001b[39m         cookies=cookies,\n\u001b[32m   1869\u001b[39m         auth=auth,\n\u001b[32m   1870\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1871\u001b[39m         timeout=timeout,\n\u001b[32m   1872\u001b[39m         extensions=extensions,\n\u001b[32m   1873\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_transports/default.py:393\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_async_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLaMA3 ì‘ë‹µ: ## (\"entity\"<|>Ebenezer Scrooge<|>person<|>He was a bitter old man with a heart full of coldness and stone. He had no love for Christmas or its traditions, and he spent most of his time alone, away from his nephew's family.)\n",
      "## (\"entity\"<|>Nephew<|>person<|>He was Scrooge's nephew, who lived with his wife and children, celebrating Christmas in a warm and loving manner.)\n",
      "## (\"entity\"<|>Sister<|>person<|>She was Scrooge's sister, who was kind and gentle, but also had a sense of mischief and playfulness.)\n",
      "## (\"entity\"<|>Postboy<|>person<|>He was a tired and worn-out postboy, who had been working all day and just wanted to rest and enjoy the Christmas celebrations.)\n",
      "## (\"entity\"<|>Dick Wilkins<|>person<|>He was Scrooge's fellow-'prentice, who was young and full of life, enjoying the festive atmosphere and celebrating with his friends.)\n",
      "## (\"entity\"<|>Warehouse<|>organization<|>It was a large warehouse where Fezziwig held Christmas celebrations for his employees, filled with music, dance, and laughter.)\n",
      "## (\"relationship\"<|>Master Scrooge<|>Nephew<|>Scrooge's nephew tried to reach out to him and bring some joy into his life, but Scrooge was too bitter and cold-hearted to respond.<|>6)\n",
      "## (\"relationship\"<|>Schoolmaster<|>Sister<|>The schoolmaster forced the sister to learn and study, which made her unhappy and rebellious.<|>4)\n",
      "\n",
      "##<|>COMPLETE|>\n",
      "â ™ Processed 1(25%) chunks,  10 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLaMA3 ì‘ë‹µ: Here are the additional entities:\n",
      "\n",
      "## \"entity\"<|>\"Ghost of Christmas Past\"<|>event<|>\"A spirit that appears to Scrooge and guides him on a journey through his past\"<|>\n",
      "\n",
      "## \"entity\"<|>\"Ghost of Christmas Present\"<|>event<|>\"A spirit that appears to Scrooge and guides him on a journey through his present, revealing the struggles of those around him\"<|>\n",
      "\n",
      "## \"entity\"<|>\"Ghost of Christmas Yet to Come\"<|>event<|>\"A spirit that appears to Scrooge and guides him on a journey through his future, showing him a possible outcome if he does not change his ways\"<|>\n",
      "\n",
      "## \"entity\"<|>\"Jacob Marley's Ghost\"<|>event<|>\"The ghost of Jacob Marley, Scrooge's former business partner who died in a state of despair due to their greedy and selfish ways\"<|>\n",
      "\n",
      "## \"entity\"<|>\"Bob Cratchit's Family\"<|>person<|>\"The family of Bob Cratchit, including his wife and children, who are struggling to make ends meet despite Scrooge's mistreatment of them\"<|>\n",
      "\n",
      "## \"entity\"<|>\"Mansion\"<|>geo<|>\"A large house that was once grand but has fallen into disrepair, symbolizing the decline of Scrooge's own life and values\"<|>\n",
      "\n",
      "## \"entity\"<|>\"School\"<|>geo<|>\"A school where a solitary child is left alone, highlighting the neglect and isolation that many children experience\"<|>\n",
      "\n",
      "## \"entity\"<|>\"Mice\"<|>person<|>\"Small creatures that live in the walls of the old mansion, representing the quiet desperation and hopelessness that can be felt by those who are forgotten or overlooked\"<|>\n",
      "\n",
      "## COMPLETE|>\n",
      "â ¹ Processed 2(50%) chunks,  10 entities(duplicated), 5 relations(duplicated)\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# [3] ë¬¸ì„œ ì‚½ì… (í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ë©´ ì €ì¥ë¨)\n",
    "with open(\"./book.txt\") as f:\n",
    "    text = f.read()\n",
    "    graph_func.insert(text)  # ìë™ìœ¼ë¡œ chunking, graph êµ¬ì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì—‘ì‚¬ì› í™œìš© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nano_graphrag import GraphRAG\n",
    "\n",
    "# âœ… EXAONE ë¹„ë™ê¸° LLM í•¨ìˆ˜\n",
    "async def exaone_generate(prompt, system_prompt=None, history_messages=[], **kwargs):\n",
    "    async with httpx.AsyncClient(timeout=180.0) as client:\n",
    "        response = await client.post(\n",
    "            \"http://localhost:8000/generate\",  # ì„œë²„ ì£¼ì†Œ ë§ê²Œ ìˆ˜ì •\n",
    "            json={\"prompt\": prompt}\n",
    "        )\n",
    "        return response.json()[\"result\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: jhgan/ko-sroberta-multitask\n"
     ]
    }
   ],
   "source": [
    "# âœ… SentenceTransformer ë¡œë“œ\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ì•ˆì „í•˜ê²Œ ì˜ ì‘ë™í•˜ëŠ” ëª¨ë¸\n",
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "\n",
    "# âœ… nano-graphragì— ë§ëŠ” embedding function wrapper\n",
    "def wrap_embedding_func_with_attrs(embedding_dim, max_token_size):\n",
    "    def decorator(func):\n",
    "        func.embedding_dim = embedding_dim\n",
    "        func.max_token_size = max_token_size\n",
    "        return func\n",
    "    return decorator\n",
    "\n",
    "@wrap_embedding_func_with_attrs(embedding_dim=384, max_token_size=512)\n",
    "async def local_embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    return model.encode(texts, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Creating working directory ./my_graph_kor_exaone\n",
      "INFO:nano-graphrag:Load KV full_docs with 0 data\n",
      "INFO:nano-graphrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-graphrag:Load KV llm_response_cache with 0 data\n",
      "INFO:nano-graphrag:Load KV community_reports with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 384, 'metric': 'cosine', 'storage_file': './my_graph_kor_exaone/vdb_entities.json'} 0 data\n"
     ]
    }
   ],
   "source": [
    "# âœ… GraphRAG ê°ì²´ ìƒì„±\n",
    "graph_func = GraphRAG(\n",
    "    working_dir=\"./my_graph_kor_exaone\",\n",
    "    best_model_func=exaone_generate,  # â¬…ï¸ ì—¬ê¸°ë§Œ ë°”ë€ í¬ì¸íŠ¸!\n",
    "    embedding_func=local_embedding_func,\n",
    "    chunk_token_size=100000,\n",
    "    chunk_overlap_token_size=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:[New Docs] inserting 10 docs\n",
      "INFO:nano-graphrag:[New Chunks] inserting 10 chunks\n",
      "INFO:nano-graphrag:[Entity Extraction]...\n",
      "INFO:nano-graphrag:Writing graph with 0 nodes, 0 edges\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mhair_data/blog_allure.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m docs = df[\u001b[33m\"\u001b[39m\u001b[33më³¸ë¬¸\u001b[39m\u001b[33m\"\u001b[39m].dropna().astype(\u001b[38;5;28mstr\u001b[39m).tolist()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m graph_func.ainsert(docs[:\u001b[32m10\u001b[39m])  \u001b[38;5;66;03m# âœ… ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë¨\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/graphrag.py:328\u001b[39m, in \u001b[36mGraphRAG.ainsert\u001b[39m\u001b[34m(self, string_or_strings)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# ---------- extract/summary entity and upsert to graph\u001b[39;00m\n\u001b[32m    327\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m[Entity Extraction]...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m maybe_new_kg = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.entity_extraction_func(\n\u001b[32m    329\u001b[39m     inserting_chunks,\n\u001b[32m    330\u001b[39m     knwoledge_graph_inst=\u001b[38;5;28mself\u001b[39m.chunk_entity_relation_graph,\n\u001b[32m    331\u001b[39m     entity_vdb=\u001b[38;5;28mself\u001b[39m.entities_vdb,\n\u001b[32m    332\u001b[39m     global_config=asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m    333\u001b[39m     using_amazon_bedrock=\u001b[38;5;28mself\u001b[39m.using_amazon_bedrock,\n\u001b[32m    334\u001b[39m )\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maybe_new_kg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    336\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mNo new entities found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_op.py:451\u001b[39m, in \u001b[36mextract_entities\u001b[39m\u001b[34m(chunks, knwoledge_graph_inst, entity_vdb, global_config, using_amazon_bedrock)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(maybe_nodes), \u001b[38;5;28mdict\u001b[39m(maybe_edges)\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# use_llm_func is wrapped in ascynio.Semaphore, limiting max_async callings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    452\u001b[39m     *[_process_single_content(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ordered_chunks]\n\u001b[32m    453\u001b[39m )\n\u001b[32m    454\u001b[39m \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# clear the progress bar\u001b[39;00m\n\u001b[32m    455\u001b[39m maybe_nodes = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_op.py:388\u001b[39m, in \u001b[36mextract_entities.<locals>._process_single_content\u001b[39m\u001b[34m(chunk_key_dp)\u001b[39m\n\u001b[32m    385\u001b[39m hint_prompt = entity_extract_prompt.format(**context_base, input_text=content)\n\u001b[32m    386\u001b[39m \u001b[38;5;66;03m# print(hint_prompt[:1000])\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m final_result = \u001b[38;5;28;01mawait\u001b[39;00m use_llm_func(hint_prompt)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(final_result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    390\u001b[39m     final_result = final_result[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_utils.py:271\u001b[39m, in \u001b[36mlimit_async_func_call.<locals>.final_decro.<locals>.wait_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(waitting_time)\n\u001b[32m    270\u001b[39m __current_size += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    272\u001b[39m __current_size -= \u001b[32m1\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mexaone_generate\u001b[39m\u001b[34m(prompt, system_prompt, history_messages, **kwargs)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexaone_generate\u001b[39m(prompt, system_prompt=\u001b[38;5;28;01mNone\u001b[39;00m, history_messages=[], **kwargs):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m httpx.AsyncClient(timeout=\u001b[32m180.0\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m client.post(\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:8000/generate\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# ì„œë²„ ì£¼ì†Œ ë§ê²Œ ìˆ˜ì •\u001b[39;00m\n\u001b[32m     11\u001b[39m             json={\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt}\n\u001b[32m     12\u001b[39m         )\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response.json()[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1859\u001b[39m, in \u001b[36mAsyncClient.post\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1840\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1852\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1853\u001b[39m ) -> Response:\n\u001b[32m   1854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[33;03m    Send a `POST` request.\u001b[39;00m\n\u001b[32m   1856\u001b[39m \n\u001b[32m   1857\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1861\u001b[39m         url,\n\u001b[32m   1862\u001b[39m         content=content,\n\u001b[32m   1863\u001b[39m         data=data,\n\u001b[32m   1864\u001b[39m         files=files,\n\u001b[32m   1865\u001b[39m         json=json,\n\u001b[32m   1866\u001b[39m         params=params,\n\u001b[32m   1867\u001b[39m         headers=headers,\n\u001b[32m   1868\u001b[39m         cookies=cookies,\n\u001b[32m   1869\u001b[39m         auth=auth,\n\u001b[32m   1870\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1871\u001b[39m         timeout=timeout,\n\u001b[32m   1872\u001b[39m         extensions=extensions,\n\u001b[32m   1873\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_async/connection.py:76\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     72\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempted to send request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest.url.origin\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on connection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._origin\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_lock:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m             stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/httpcore/_synchronization.py:77\u001b[39m, in \u001b[36mAsyncLock.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trio_lock.acquire()\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend == \u001b[33m\"\u001b[39m\u001b[33masyncio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._anyio_lock.acquire()\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:1799\u001b[39m, in \u001b[36mLock.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1797\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_acquire:\n\u001b[32m   1798\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m AsyncIOBackend.cancel_shielded_checkpoint()\n\u001b[32m   1800\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError:\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28mself\u001b[39m.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:2350\u001b[39m, in \u001b[36mAsyncIOBackend.cancel_shielded_checkpoint\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m   2347\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2348\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcancel_shielded_checkpoint\u001b[39m(\u001b[38;5;28mcls\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2349\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m CancelScope(shield=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2350\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:640\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Coroutine that completes after a given time (in seconds).\"\"\"\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delay <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m __sleep0()\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    643\u001b[39m loop = events.get_running_loop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:634\u001b[39m, in \u001b[36m__sleep0\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;129m@types\u001b[39m.coroutine\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sleep0\u001b[39m():\n\u001b[32m    627\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Skip one event loop run cycle.\u001b[39;00m\n\u001b[32m    628\u001b[39m \n\u001b[32m    629\u001b[39m \u001b[33;03m    This is a private helper for 'asyncio.sleep()', used\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    632\u001b[39m \u001b[33;03m    instead of creating a Future object.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ë¸”ë¡œê·¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('hair_data/blog_allure.csv')\n",
    "\n",
    "docs = df[\"ë³¸ë¬¸\"].dropna().astype(str).tolist()\n",
    "await graph_func.ainsert(docs[:10])  # âœ… ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-ëª©í‘œ-\\në‹¤ìŒì— ì œì‹œëœ í…ìŠ¤íŠ¸ ë¬¸ì„œì™€ ì—”í‹°í‹° íƒ€ì… ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ íƒ€ì…ì— í•´ë‹¹í•˜ëŠ” ì—”í‹°í‹°ë“¤ì„ ëª¨ë‘ ì‹ë³„í•˜ê³  ì´ë“¤ ê°„ì˜ ëª…í™•í•œ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\\n\\n-ë‹¨ê³„-\\n1. ì—”í‹°í‹° ì‹ë³„:\\n   ë¬¸ì„œ ë‚´ì—ì„œ ì§€ì •ëœ ì—”í‹°í‹° íƒ€ì…({entity_types})ì— í•´ë‹¹í•˜ëŠ” ì—”í‹°í‹°ë¥¼ ëª¨ë‘ ì°¾ì•„ë‚´ê³ , ê°ê°ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤:\\n   - entity_name: ì—”í‹°í‹°ì˜ ì´ë¦„ (ëª¨ë‘ ëŒ€ë¬¸ìë¡œ í‘œê¸°)\\n   - entity_type: ì§€ì •ëœ ì—”í‹°í‹° íƒ€ì… ì¤‘ í•˜ë‚˜\\n   - entity_description: í•´ë‹¹ ì—”í‹°í‹°ì˜ íŠ¹ì„±ê³¼ í™œë™ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…\\n\\n   ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤:\\n   (\"entity\"<|><ì—”í‹°í‹°_ì´ë¦„><|><ì—”í‹°í‹°_íƒ€ì…><|><ì—”í‹°í‹°_ì„¤ëª…>)\\n\\n2. ê´€ê³„ ì¶”ì¶œ:\\n   ìœ„ì—ì„œ ì‹ë³„í•œ ì—”í‹°í‹°ë“¤ ì¤‘ ëª…í™•íˆ ê´€ë ¨ëœ ì—”í‹°í‹° ìŒ(source_entity, target_entity)ì„ ì°¾ê³ , ê°ê°ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤:\\n   - source_entity: ê´€ê³„ì˜ ì¶œë°œì ì´ ë˜ëŠ” ì—”í‹°í‹° ì´ë¦„\\n   - target_entity: ê´€ê³„ì˜ ë„ì°©ì ì´ ë˜ëŠ” ì—”í‹°í‹° ì´ë¦„\\n   - relationship_description: ë‘ ì—”í‹°í‹°ê°€ ê´€ë ¨ ìˆë‹¤ê³  íŒë‹¨í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥\\n   - relationship_strength: ê´€ê³„ì˜ ê°•ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ì (1â€“10 ì‚¬ì´)\\n\\n   ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤:\\n   (\"relationship\"<|><ì¶œë°œ_ì—”í‹°í‹°><|><ë„ì°©_ì—”í‹°í‹°><|><ê´€ê³„_ì„¤ëª…><|><ê´€ê³„_ê°•ë„>)\\n\\n3. ì¶œë ¥:\\n   ì—”í‹°í‹°ì™€ ê´€ê³„ ì •ë³´ë¥¼ ëª¨ë‘ **í•˜ë‚˜ì˜ ëª©ë¡**ìœ¼ë¡œ ë¬¶ì–´ ì¶œë ¥í•˜ë©°, ê° í•­ëª©ì€ **{record_delimiter}** ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.\\n   ì¶œë ¥ì˜ ë§ˆì§€ë§‰ì€ ë°˜ë“œì‹œ {completion_delimiter} ë¡œ ë§ˆë¬´ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\\n\\n######################\\n-ì˜ˆì‹œ-\\n######################\\nEntity_types: [person, technology, mission, organization, location]\\nText:\\nAlexëŠ” í„±ì„ ê½‰ ê¹¨ë¬¼ë©° ë¶„ë…¸ë¥¼ ì°¸ëŠ”ë‹¤. ê·¸ì˜ ì˜†ì— ìˆëŠ” TaylorëŠ” ê¶Œìœ„ì ì¸ íƒœë„ë¡œ ëª¨ë“  ê±¸ ì§€ì‹œí•œë‹¤. ê·¸ë“¤ ì‚¬ì´ì—ëŠ” ê¸´ì¥ê°ì´ íë¥´ê³ , Jordanê³¼ì˜ í˜‘ì—…ì€ ë§ˆì¹˜ ê·¸ ê¶Œìœ„ì— ëŒ€í•œ ì¡°ìš©í•œ ì €í•­ì²˜ëŸ¼ ëŠê»´ì¡Œë‹¤.\\n\\nTaylorëŠ” ëœ»ë°–ì˜ í–‰ë™ì„ í•œë‹¤. Jordan ì˜†ì—ì„œ ë©ˆì¶° ì¥ë¹„ë¥¼ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ë°”ë¼ë³´ë©° ë§í–ˆë‹¤. \"ì´ ê¸°ìˆ ì´ ì´í•´ëœë‹¤ë©´, ëª¨ë“  ê²ƒì„ ë°”ê¿€ ìˆ˜ ìˆì–´ìš”.\"\\n\\nê·¸ ë§ì€ ê·¸ë“¤ì˜ ì‹ ë…ê³¼ë„ ë§ë‹¿ì•„ ìˆì—ˆë‹¤. AlexëŠ” ê·¸ ìˆœê°„ì„ ìŠì§€ ëª»í•  ê²ƒì´ë‹¤.\\n################\\nOutput:\\n(\"entity\"<|>\"ALEX\"<|>\"PERSON\"<|>\"AlexëŠ” íŒ€ì˜ ì¼ì›ì´ë©°, Taylorì˜ ê¶Œìœ„ì ì¸ íƒœë„ì— ë°˜ì‘í•˜ë©° ë‚´ë¶€ ê°ˆë“±ì„ ê²½í—˜í•˜ëŠ” ì¸ë¬¼ì…ë‹ˆë‹¤.\"){record_delimiter}\\n(\"entity\"<|>\"TAYLOR\"<|>\"PERSON\"<|>\"TaylorëŠ” ê¶Œìœ„ì ì´ê³  ì§€ì‹œì ì¸ ë¦¬ë”ë¡œ ë¬˜ì‚¬ë˜ë©°, ê¸°ìˆ  ì¥ë¹„ì— ëŒ€í•´ ê²½ì™¸ê°ì„ ë³´ì´ëŠ” ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\"){record_delimiter}\\n(\"entity\"<|>\"JORDAN\"<|>\"PERSON\"<|>\"Jordanì€ ê¸°ìˆ  ê°œë°œì— í—Œì‹ ì ì´ë©° Taylorì™€ì˜ ìƒí˜¸ì‘ìš©ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"){record_delimiter}\\n(\"entity\"<|>\"DEVICE\"<|>\"TECHNOLOGY\"<|>\"ì´ ì¥ë¹„ëŠ” ì´ì•¼ê¸°ì˜ ì¤‘ì‹¬ ê¸°ìˆ ì´ë©°, ë¯¸ë˜ë¥¼ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.\"){record_delimiter}\\n(\"relationship\"<|>\"ALEX\"<|>\"TAYLOR\"<|>\"AlexëŠ” Taylorì˜ ê¶Œìœ„ì ì¸ íƒœë„ì— ì˜í–¥ì„ ë°›ê³  ìˆìœ¼ë©°, ê·¸ í–‰ë™ì„ ê´€ì°°í•©ë‹ˆë‹¤.\"{record_delimiter}7){record_delimiter}\\n(\"relationship\"<|>\"TAYLOR\"<|>\"JORDAN\"<|>\"TaylorëŠ” Jordan ì˜†ì—ì„œ ì¥ë¹„ë¥¼ ê´€ì°°í•˜ë©° ì ì¬ì ì¸ í˜‘ë ¥ ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\"{record_delimiter}6){record_delimiter}\\n(\"relationship\"<|>\"TAYLOR\"<|>\"DEVICE\"<|>\"TaylorëŠ” ì¥ë¹„ë¥¼ ê²½ì™¸ì‹¬ì„ ê°€ì§€ê³  ë°”ë¼ë³´ë©° ê¸°ìˆ ì— ëŒ€í•œ ì¸ì‹ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.\"{record_delimiter}9){completion_delimiter}\\n\\n######################\\n-ì‹¤ì œ ì…ë ¥-\\n######################\\nEntity_types: {entity_types}\\nText: {input_text}\\n######################\\nOutput:\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "# EXAONE API í˜¸ì¶œ í•¨ìˆ˜\n",
    "async def exaone_generate(prompt):\n",
    "    async with httpx.AsyncClient(timeout=60.0) as client:\n",
    "        res = await client.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": \"exaone3.5:7.8b\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "        return res.json()[\"response\"]\n",
    "\n",
    "# GraphRAGì—ì„œ ì‚¬ìš©í•  LLM í•¨ìˆ˜\n",
    "async def my_custom_llm(prompt, system_prompt=None, history_messages=[], **kwargs):\n",
    "    full_prompt = \"\"\n",
    "    if system_prompt:\n",
    "        full_prompt += f\"[System]\\n{system_prompt}\\n\\n\"\n",
    "    for message in history_messages:\n",
    "        role = message.get(\"role\", \"user\")\n",
    "        content = message.get(\"content\", \"\")\n",
    "        full_prompt += f\"[{role.capitalize()}]\\n{content}\\n\\n\"\n",
    "    full_prompt += f\"[User]\\n{prompt}\"\n",
    "\n",
    "    return await exaone_generate(full_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nano_graphrag import GraphRAG\n",
    "import pandas as pd\n",
    "\n",
    "# GraphRAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "graph_func = GraphRAG(\n",
    "    working_dir=\"./my_graph_kor_exaone\",\n",
    "    best_model_func=my_custom_llm,         # âœ… EXAONE ê¸°ë°˜ LLM\n",
    "    embedding_func=local_embedding_func,   # âœ… SentenceTransformer ì„ë² ë”©\n",
    "    chunk_token_size=100000,\n",
    "    chunk_overlap_token_size=0,\n",
    ")\n",
    "\n",
    "# ë¸”ë¡œê·¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('hair_data/blog_allure.csv')\n",
    "docs = df[\"ë³¸ë¬¸\"].dropna().astype(str).tolist()\n",
    "\n",
    "# ë¬¸ì„œ ì‚½ì…\n",
    "graph_func.insert(docs[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from nano_graphrag.prompt_kr import PROMPTS\n",
    "\n",
    "# ë¹„ë™ê¸° EXAONE í˜¸ì¶œ í•¨ìˆ˜\n",
    "async def exaone_generate(prompt):\n",
    "    async with httpx.AsyncClient(timeout=180.0) as client:  # 60ì´ˆë¡œ ëŠ˜ë¦¼\n",
    "        res = await client.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": \"exaone3.5:7.8b\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "        return res.json()[\"response\"]\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì—”í‹°í‹° ë° ê´€ê³„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "async def extract_entities_and_relationships(input_text, entity_types):\n",
    "    prompt_template = PROMPTS[\"entity_extraction\"]\n",
    "\n",
    "    # êµ¬ì„±ìš”ì†Œ\n",
    "    record_delimiter = \"<R>\"\n",
    "    completion_delimiter = \"<END>\"\n",
    "\n",
    "    # í¬ë§·íŒ…ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    formatted_prompt = prompt_template.format(\n",
    "        entity_types=entity_types,\n",
    "        input_text=input_text,\n",
    "        record_delimiter=record_delimiter,\n",
    "        completion_delimiter=completion_delimiter\n",
    "    )\n",
    "\n",
    "    # EXAONEì— ì „ë‹¬í•˜ê³  ê²°ê³¼ ë°›ê¸°\n",
    "    output = await exaone_generate(formatted_prompt)\n",
    "\n",
    "    # ê²°ê³¼ íŒŒì‹±ì€ í•„ìš” ì‹œ ì¶”ê°€\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<R>(\"entity\"<|>\"OPENAI\"<|>\"ORGANIZATION\"<|>\"OpenAIëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê°œë°œì„ ì£¼ë„í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ì—°êµ¬ì†Œì´ë©°, GPT ì‹œë¦¬ì¦ˆë¥¼ í†µí•´ ìƒì„±í˜• AI ë¶„ì•¼ì˜ í˜ì‹ ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.\")<R>\n",
      "<R>(\"entity\"<|>\"GPT SERIES\"<|>\"TECHNOLOGY\"<|>\"GPT ì‹œë¦¬ì¦ˆëŠ” OpenAIê°€ ê°œë°œí•œ ê³ ê¸‰ ì–¸ì–´ ëª¨ë¸ë¡œì„œ ìƒì„±í˜• AI ê¸°ìˆ ì˜ ë°œì „ì— ì¤‘ì¶”ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.\")<R>\n",
      "<R>(\"entity\"<|>\"AZURE\"<|>\"ORGANIZATION\"<|>\"Microsoftì˜ í´ë¼ìš°ë“œ í”Œë«í¼ìœ¼ë¡œ, ì—¬ê¸°ì„œ OpenAIì˜ AI ê¸°ìˆ ì´ ë°°í¬ë˜ì–´ ê¸°ì—…ê³¼ ê°œë°œìë“¤ì—ê²Œ ì œê³µë©ë‹ˆë‹¤.\")<R>\n",
      "<R>(\"relationship\"<|>\"OPENAI\"<|>\"GPT SERIES\"<|>\"OpenAIëŠ” GPT ì‹œë¦¬ì¦ˆ ê¸°ìˆ ì„ í†µí•´ ìƒì„±í˜• AI ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì£¼ë„í•˜ë©° í•µì‹¬ ê¸°ìˆ  ì—­í• ì„ í•©ë‹ˆë‹¤.\"<R>9)<R>\n",
      "<R>(\"relationship\"<|>\"OPENAI\"<|>\"AZURE\"<|>\"OpenAIëŠ” Microsoftì˜ Azure í”Œë«í¼ì„ í†µí•´ ê¸°ìˆ  ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•¨ìœ¼ë¡œì¨ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ ì‹œì¥ ì ‘ê·¼ì„±ì„ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"<R>8)<R>\n",
      "<R>(\"relationship\"<|>\"GPT SERIES\"<|>\"AZURE\"<|>\"GPT ì‹œë¦¬ì¦ˆ ê¸°ìˆ ì€ Azureë¥¼ í†µí•´ í´ë¼ìš°ë“œ ê¸°ë°˜ìœ¼ë¡œ ì œê³µë˜ë©°, ì´ë¥¼ í†µí•´ ì‚¬ìš©ìë“¤ì—ê²Œ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ AI ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\"<R>8)<R>\n",
      "<R>(\"entity\"<|>\"2023\"<|>\"YEAR\"<|>\"2023ë…„ì€ OpenAIì™€ Microsoft ê°„ì˜ ì¤‘ìš”í•œ í˜‘ë ¥ì´ ì´ë£¨ì–´ì§„ í•´ë¡œ, íŠ¹íˆ Azureë¥¼ í†µí•œ AI ì„œë¹„ìŠ¤ ë°°í¬ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.\")<R>\n",
      "<R>(\"relationship\"<|>\"OPENAI\"<|>\"2023\"<|>\"2023ë…„ì˜ ì‚¬ê±´ì€ OpenAIì˜ ê¸°ìˆ ì  ë°œì „ê³¼ ì‹œì¥ ì§„ì¶œ ì „ëµì´ ë³¸ê²©ì ìœ¼ë¡œ ì§„í–‰ëœ í•´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\"<R>7)<R>\n",
      "<R>(\"relationship\"<|>\"AZURE\"<|>\"2023\"<|>\"2023ë…„ì—ëŠ” Azure í”Œë«í¼ì„ í†µí•´ OpenAIì˜ AI ì„œë¹„ìŠ¤ ë°°í¬ê°€ ì´ë£¨ì–´ì ¸ í•´ë‹¹ ì—°ë„ì˜ ê¸°ìˆ ì  ì§„ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\"<R>7)<R>\n",
      "<R>\"END\"<R>\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# ì˜ˆì‹œ ì…ë ¥\n",
    "text = \"\"\"\n",
    "OpenAIëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ì¸ê³µì§€ëŠ¥ ì—°êµ¬ì†Œë¡œ, GPT ì‹œë¦¬ì¦ˆë¥¼ í†µí•´ ìƒì„±í˜• AIì˜ í•œê³„ë¥¼ í™•ì¥í•˜ê³  ìˆë‹¤.\n",
    "2023ë…„ì—ëŠ” Microsoftì™€ì˜ í˜‘ë ¥ì„ í†µí•´ Azureì— AI ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•˜ê¸°ë„ í–ˆë‹¤.\n",
    "\"\"\"\n",
    "entity_types = [\"organization\", \"technology\", \"year\"]\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "result = asyncio.run(extract_entities_and_relationships(text, entity_types))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT í™œìš©\n",
    "- í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ë¡¤ë§í•œ ê²ƒì„ documentë¡œ í™œìš©í•˜ì—¬ graphragì— ì ìš©\n",
    "- gpt-4o-minië¥¼ í™œìš©í•  ì˜ˆì •ì´ë©°, promptë¥¼ í•œêµ­ì–´ë¡œ ë°”ê¾¸ëŠ”ê²Œ í•„ìš”í•¨ \n",
    "\n",
    "### ì½”ë“œ êµ¬í˜„\n",
    "1. ì „ì²´ ì½”ë“œ íë¦„ì— ëŒ€í•´ ëª¨ë“ˆí™” ë˜ì–´ ìˆëŠ” ê²ƒì„ ë‚´ ë°©ì‹ëŒ€ë¡œ ë°”ê¾¸ê¸° \n",
    "    - ì´ë¥¼ ìœ„í•´ ì „ì²´ ì½”ë“œì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•¨\n",
    "\n",
    "2. gpt-4o-minië§Œ ì‚¬ìš©í•  ì˜ˆì •ì´ë©° promptë¥¼ í•œêµ­ì–´ë¡œ ë°”ê¿ˆ \n",
    "    - ì´ë•Œ, ìš°ë¦¬ì˜ ë¬¸ì„œì— taskì— ë§ê²Œ promptë¥¼ ì¡°ì •í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•¨ \n",
    "    - í•œêµ­ì–´ documentë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ë„ í•„ìš”í•¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # .env íŒŒì¼ì— OPENAI_API_KEYê°€ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nano_graphrag._llm import openai_complete_if_cache\n",
    "\n",
    "async def my_custom_llm(prompt, system_prompt=None, history_messages=[], **kwargs):\n",
    "    return await openai_complete_if_cache(\n",
    "        \"gpt-4o-mini\",  # ì›í•˜ëŠ” ëª¨ë¸\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: jhgan/ko-sroberta-multitask\n",
      "/Users/mac/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ì•ˆì •ì ìœ¼ë¡œ ë¡œë”© ê°€ëŠ¥í•œ í•œêµ­ì–´ SBERT ëª¨ë¸\n",
    "model_name = 'jhgan/ko-sroberta-multitask'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# nano-graphragì—ì„œ ìš”êµ¬í•˜ëŠ” ë˜í•‘\n",
    "def wrap_embedding_func_with_attrs(embedding_dim, max_token_size):\n",
    "    def decorator(func):\n",
    "        func.embedding_dim = embedding_dim\n",
    "        func.max_token_size = max_token_size\n",
    "        return func\n",
    "    return decorator\n",
    "\n",
    "@wrap_embedding_func_with_attrs(embedding_dim=768, max_token_size=512)\n",
    "async def local_embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ SBERT ì„ë² ë”©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    return model.encode(texts, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Creating working directory ./my_graph_kor\n",
      "INFO:nano-graphrag:Load KV full_docs with 0 data\n",
      "INFO:nano-graphrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-graphrag:Load KV llm_response_cache with 0 data\n",
      "INFO:nano-graphrag:Load KV community_reports with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './my_graph_kor/vdb_entities.json'} 0 data\n"
     ]
    }
   ],
   "source": [
    "from nano_graphrag import GraphRAG\n",
    "\n",
    "# graph_func = GraphRAG(\n",
    "#     working_dir=\"./my_graphrag_data\",\n",
    "#     best_model_func=my_custom_llm , # ì—¬ê¸°ì„œ ì§€ì •\n",
    "#     embedding_func=local_embedding_func,  # ì—¬ê¸°ì„œ ì§€ì •\n",
    "# )\n",
    "graph_func = GraphRAG(\n",
    "    working_dir=\"./my_graph_kor\",\n",
    "    best_model_func=my_custom_llm,\n",
    "    embedding_func=local_embedding_func,\n",
    "\n",
    "    # âœ… ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì•„ì£¼ í¬ê²Œ ì„¤ì •í•´ì„œ \"ì ˆëŒ€ ìë¥´ì§€ ì•Šê²Œ\" í•¨\n",
    "    chunk_token_size=100000,\n",
    "    chunk_overlap_token_size=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:[New Docs] inserting 2 docs\n",
      "INFO:nano-graphrag:[New Chunks] inserting 2 chunks\n",
      "INFO:nano-graphrag:[Entity Extraction]...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â ™ Processed 1(50%) chunks,  6 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â ¹ Processed 2(100%) chunks,  10 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Inserting 10 vectors to entities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.14it/s]\n",
      "INFO:nano-graphrag:[Community Report]...\n",
      "INFO:nano-graphrag:Writing graph with 10 nodes, 0 edges\n"
     ]
    },
    {
     "ename": "EmptyNetworkError",
     "evalue": "EmptyNetworkError",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyNetworkError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m df= pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mhair_data/naver_blog_per3.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m docs = df[\u001b[33m\"\u001b[39m\u001b[33mìš”ì•½\u001b[39m\u001b[33m\"\u001b[39m].dropna().astype(\u001b[38;5;28mstr\u001b[39m).tolist()  \u001b[38;5;66;03m# ğŸ”¥ í–‰ í•˜ë‚˜ = í•˜ë‚˜ì˜ ì²­í¬ë¡œ ì‚¬ìš©ë¨\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mgraph_func\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/graphrag.py:222\u001b[39m, in \u001b[36mGraphRAG.insert\u001b[39m\u001b[34m(self, string_or_strings)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minsert\u001b[39m(\u001b[38;5;28mself\u001b[39m, string_or_strings):\n\u001b[32m    221\u001b[39m     loop = always_get_an_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mainsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring_or_strings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/graphrag.py:341\u001b[39m, in \u001b[36mGraphRAG.ainsert\u001b[39m\u001b[34m(self, string_or_strings)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# ---------- update clusterings of graph\u001b[39;00m\n\u001b[32m    340\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m[Community Report]...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_entity_relation_graph.clustering(\n\u001b[32m    342\u001b[39m     \u001b[38;5;28mself\u001b[39m.graph_cluster_algorithm\n\u001b[32m    343\u001b[39m )\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m generate_community_report(\n\u001b[32m    345\u001b[39m     \u001b[38;5;28mself\u001b[39m.community_reports, \u001b[38;5;28mself\u001b[39m.chunk_entity_relation_graph, asdict(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    346\u001b[39m )\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# ---------- commit upsertings and indexing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_storage/gdb_networkx.py:138\u001b[39m, in \u001b[36mNetworkXStorage.clustering\u001b[39m\u001b[34m(self, algorithm)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m algorithm \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._clustering_algorithms:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClustering algorithm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not supported\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._clustering_algorithms[algorithm]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_graphrag/_storage/gdb_networkx.py:204\u001b[39m, in \u001b[36mNetworkXStorage._leiden_clustering\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraspologic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hierarchical_leiden\n\u001b[32m    203\u001b[39m graph = NetworkXStorage.stable_largest_connected_component(\u001b[38;5;28mself\u001b[39m._graph)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m community_mapping = \u001b[43mhierarchical_leiden\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mglobal_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_graph_cluster_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mglobal_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgraph_cluster_seed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m node_communities: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]] = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    211\u001b[39m __levels = defaultdict(\u001b[38;5;28mset\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<@beartype(graspologic.partition.leiden.hierarchical_leiden) at 0x352010ea0>:304\u001b[39m, in \u001b[36mhierarchical_leiden\u001b[39m\u001b[34m(__beartype_object_14250901696, __beartype_object_14249558976, __beartype_getrandbits, __beartype_get_violation, __beartype_conf, __beartype_object_4381911528, __beartype_object_19314356160, __beartype_object_14249564032, __beartype_object_14264959904, __beartype_object_14264958944, __beartype_func, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIworkspace/torchspace/nano-graphrag/nano_env/lib/python3.11/site-packages/graspologic/partition/leiden.py:588\u001b[39m, in \u001b[36mhierarchical_leiden\u001b[39m\u001b[34m(graph, max_cluster_size, starting_communities, extra_forced_iterations, resolution, randomness, use_modularity, random_seed, weight_attribute, is_weighted, weight_default, check_directed)\u001b[39m\n\u001b[32m    580\u001b[39m     node_count, edges = _adjacency_matrix_to_edge_list(\n\u001b[32m    581\u001b[39m         graph, identifier, check_directed, is_weighted, weight_default\n\u001b[32m    582\u001b[39m     )\n\u001b[32m    584\u001b[39m native_friendly_communities = _community_python_to_native(\n\u001b[32m    585\u001b[39m     starting_communities, identifier\n\u001b[32m    586\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m hierarchical_clusters_native = \u001b[43mgn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhierarchical_leiden\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43medges\u001b[49m\u001b[43m=\u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstarting_communities\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnative_friendly_communities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_forced_iterations\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_modularity\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_modularity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    599\u001b[39m result_partitions = HierarchicalClusters()\n\u001b[32m    600\u001b[39m all_nodes = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mEmptyNetworkError\u001b[39m: EmptyNetworkError"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd \n",
    "df= pd.read_csv('hair_data/naver_blog_per3.csv')\n",
    "docs = df[\"ìš”ì•½\"].dropna().astype(str).tolist()  # ğŸ”¥ í–‰ í•˜ë‚˜ = í•˜ë‚˜ì˜ ì²­í¬ë¡œ ì‚¬ìš©ë¨\n",
    "graph_func.insert(docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Revtrieved 6 communities\n",
      "INFO:nano-graphrag:Grouping to 1 groups for global search\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:nano-graphrag:JSON data successfully extracted.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ë´„ì— ì–´ìš¸ë¦¬ëŠ” í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ\n",
      "\n",
      "ë‹¹ì‹ ì´ ë‹¬ê±€í˜• ì–¼êµ´ì´ë¼ë©´, ë´„ ì‹œì¦Œì— ì˜ ì–´ìš¸ë¦´ ì—¬ëŸ¬ ê°€ì§€ í—¤ì–´ìŠ¤íƒ€ì¼ì´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ë‘ ê°€ì§€ ìŠ¤íƒ€ì¼ê³¼ í•¨ê»˜ ê·¸ íŠ¹ì§•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 1. ê¹»ì ë¨¸ë¦¬ ìŠ¤íƒ€ì¼\n",
      "\n",
      "í˜„ì¬ ê¹»ì ë¨¸ë¦¬ ìŠ¤íƒ€ì¼ì´ í° ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤. ì´ ìŠ¤íƒ€ì¼ì€ ìš°ì•„í•¨ì„ ê°•ì¡°í•˜ë©°, ë´„ì˜ ê³„ì ˆì  ë¯¸ì™€ ì˜ ë§ì•„ë–¨ì–´ì§‘ë‹ˆë‹¤. ë‹¬ê±€í˜• ì–¼êµ´ì— ì í•©í•œ ì´ ìŠ¤íƒ€ì¼ì€ ì–¼êµ´ì˜ ìœ¤ê³½ì„ ë¶€ê°ì‹œí‚¤ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§¤ë ¥ì„ ë”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë´„ì—ëŠ” ì´ ìŠ¤íƒ€ì¼ì´ í•œì¸µ ë” ë¹›ì„ ë°œí•  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "### 2. íˆë©” ì»·\n",
      "\n",
      "íˆë©” ì»· ë˜í•œ ì¶”ì²œí•´ ë“œë¦´ ë§Œí•œ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤. ì´ ì»·ì€ ê¸´ ìŠ¬ë¦­ ë±…ê³¼ ë’¤ë¡œ íë¥´ëŠ” ê¸´ ë¨¸ë¦¬ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì–¼êµ´í˜•ì— ì˜ ì–´ìš¸ë¦¬ëŠ” ì´ ìŠ¤íƒ€ì¼ì€ íŠ¹íˆ ë‹¬ê±€í˜• ì–¼êµ´ì— flatteringí•œ ì„ íƒì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë´„ íŒ¨ì…˜ê³¼ ì˜ ì–´ìš°ëŸ¬ì ¸ ì¸ê¸°ê°€ ìƒìŠ¹í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë¯€ë¡œ, ì‹œë„í•´ ë³¼ ë§Œí•œ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 3. ì•¡ì„¸ì„œë¦¬ ì¶”ê°€\n",
      "\n",
      "í—¤ì–´ìŠ¤íƒ€ì¼ì„ í•œì¸µ ë” ë¹›ë‚˜ê²Œ í•˜ë ¤ë©´ ì•¡ì„¸ì„œë¦¬ì˜ ì—­í• ë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ìŠ¤í”„ë§ ì‹œì¦Œì— ì˜ ì–´ìš¸ë¦¬ëŠ” í—¤ì–´ í´ë¦½ì´ë‚˜ ë² ë ˆëª¨ ê°™ì€ ì•¡ì„¸ì„œë¦¬ë¥¼ ì¶”ê°€í•˜ë©´, ìŠ¤íƒ€ì¼ì— ë§¤ë ¥ì„ ë”í•˜ê³  ë´„ì˜ ê²½ì¾Œí•œ ëŠë‚Œì„ ê°•í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ, ë‹¬ê±€í˜• ì–¼êµ´ì—ëŠ” ê¹»ì ë¨¸ë¦¬ì™€ íˆë©” ì»·ì´ ì˜ ì–´ìš¸ë¦¬ë©°, ë‹¤ì–‘í•œ ì•¡ì„¸ì„œë¦¬ë¥¼ í™œìš©í•˜ë©´ ë´„ì˜ ë§¤ë ¥ì„ ë”ìš± ì‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìŠ¤íƒ€ì¼ì„ í†µí•´ ë‹¹ì‹ ì˜ ê°œì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Perform global graphrag search\n",
    "print(graph_func.query(\"ë‚˜ëŠ” ë‹¬ê±€í˜•ì´ê³ , ë´„ì— ì˜ ì–´ìš¸ë¦¬ëŠ” í—¤ì–´ìŠ¤íƒ€ì¼ì„ ì¶”ì²œí•´ì¤˜\"))\n",
    "\n",
    "# Perform local graphrag search (I think is better and more scalable one)\n",
    "# print(graph_func.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
